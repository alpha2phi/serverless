service: ml-api

# Create an optimized package for our functions
package:
  individually: true
  excludeDevDependencies: true
  exclude:
    - mllib/__pycache__/**
    - mllib/test_images/**
    - mllib/hello.py
    - mllib/__pycache__/**
    - __pycache__/**
    - .DS_Store
    - package.json
    - package-lock.json
    - node_modules/**
    - cache/**
    - tests/**
    - test_images/**
    - layers/**

plugins:
  - serverless-python-requirements
  - serverless-offline
  # - serverless-plugin-warmup

# layers:
#   TorchHub:
#     name: TorchHub
#     compatibleRuntimes:
#       - python3.8
#     description: PyTorch Hub
#     package:
#       artifact: layers/torch.zip

custom:
  region: ${opt:region, self:provider.region}
  stage: ${opt:stage, self:provider.stage}
  custom:
    pythonRequirements:
      dockerizepip: true
      zip: true
      slim: true
      strip: false
      nodeploy:
        - pip
        - setuptools
        - six
      usestaticcache: true
      usedownloadcache: true
      cachelocation: "./cache"

provider:
  name: aws
  runtime: python3.8
  lambdaHashingVersion: 20201221

  # support for all binary media types
  apiGateway:
    binaryMediaTypes:
      - '*/*'

  # you can overwrite defaults here
  stage: dev
  region: ap-southeast-1

functions:
  vision:
    handler: mllib/vision.main
    timeout: 30
    # layers:
    #   - { Ref: TorchHubLambdaLayer }
    events:
      - httpApi:
          path: /vision
          method: post

  # hello:
  #   handler: mllib/hello.main
  #   events:
  #     - httpApi:
  #         path: /hello
  #         method: get

