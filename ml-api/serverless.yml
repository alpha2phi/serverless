service: ml-api

# Create an optimized package for our functions
package:
  individually: true
  exclude:
    - package.json
    - package-lock.json
    - node_modules/**
    - cache/**
    - tests/**
    - test_images/**
    - layers/**
    - __pycache__/**

plugins:
  - serverless-python-requirements
  - serverless-offline
  # - serverless-plugin-warmup

layers:
  TorchHub:
    name: TorchHub
    compatibleRuntimes:
      - python3.8
    description: PyTorch Hub
    package:
      artifact: layers/torch.zip

custom:
  region: ${opt:region, self:provider.region}
  stage: ${opt:stage, self:provider.stage}

  custom:
    pythonRequirements:
    dockerizePip: true
    zip: true
    slim: true
    strip: false
    noDeploy:
      - pip
      - setuptools
      - six
    useStaticCache: true
    useDownloadCache: true
    cacheLocation: "./cache"

provider:
  name: aws
  runtime: python3.8
  lambdaHashingVersion: 20201221

  # support for all binary media types
  apiGateway:
    binaryMediaTypes:
      - '*/*'

  # you can overwrite defaults here
  stage: dev
  region: ap-southeast-1

functions:
  vision:
    handler: mllib/vision.main
    timeout: 30
    layers:
      - { Ref: TorchHubLambdaLayer }
    events:
      - httpApi:
          path: /vision
          method: post

  # hello:
  #   handler: mllib/hello.main
  #   events:
  #     - httpApi:
  #         path: /hello
  #         method: get

