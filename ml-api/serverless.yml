service: ml-api

# Create an optimized package for our functions
package:
  individually: true
  excludeDevDependencies: true
  exclude:
    - mllib/__pycache__/**
    - mllib/test_images/**
    - mllib/hello.py
    - mllib/__pycache__/**
    - __pycache__/**
    - .DS_Store
    - package.json
    - package-lock.json
    - node_modules/**
    - cache/**
    - tests/**
    - test_images/**
    - layers/**

plugins:
  - serverless-python-requirements
  - serverless-offline
  # - serverless-plugin-warmup

# layers:
#   TorchHub:
#     name: TorchHub
#     compatibleRuntimes:
#       - python3.8
#     description: PyTorch Hub
#     package:
#       artifact: layers/torch.zip

custom:
  region: ${opt:region, self:provider.region}
  stage: ${opt:stage, self:provider.stage}
  pythonRequirements:
    dockerizepip: true
    zip: true
    slim: true
    strip: false
    nodeploy:
      - pip
      - setuptools
      - six
    usestaticcache: true
    usedownloadcache: true
    cachelocation: "./.cache"
  warmup:
    events:
      - schedule: "rate(5 minutes)"
    timeout: 50

provider:
  name: aws
  runtime: python3.8
  lambdaHashingVersion: 20201221

  # support for all binary media types
  apiGateway:
    binaryMediaTypes:
      - '*/*'

  # you can overwrite defaults here
  stage: dev
  region: ap-southeast-1

functions:
  vision:
    handler: mllib/vision.main
    memorySize: 3008
    timeout: 300
    # layers:
    #   - { Ref: TorchHubLambdaLayer }
    events:
      - httpApi:
          path: /vision
          method: post
    warmup: true

  # hello:
  #   handler: mllib/hello.main
  #   events:
  #     - httpApi:
  #         path: /hello
  #         method: get

